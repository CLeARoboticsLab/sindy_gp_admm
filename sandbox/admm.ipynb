{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADMM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective p = 0.3371779420523053\n",
      "shrinkage z = [0.8928266149769695; 0.33915785046679847; 0.49161433354124096;;]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.363634307378457 0.0 0.0; 1.0722587559901684 0.7528331097368584 0.0; 0.037655611405524765 0.0008208360326767089 0.3163700505294177], [1.363634307378457 1.0722587559901684 0.037655611405524765; 0.0 0.7528331097368584 0.0008208360326767089; 0.0 0.0 0.3163700505294177])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra \n",
    "\n",
    "# objective \n",
    "function objective(A, b, lambda, x, z) \n",
    "\n",
    "    p = ( 1/2 * sum( ( A*x - b ).^2 ) + lambda*norm(z,1) ) \n",
    "\n",
    "    return p \n",
    "end \n",
    "\n",
    "# test function \n",
    "A = rand(3,3)  \n",
    "b = rand(3,1)  \n",
    "lambda = 0.1  \n",
    "x = rand(3,1)  \n",
    "z = rand(3,1) \n",
    "p = objective(A, b, lambda, x, z) \n",
    "println(\"objective p = \", p)\n",
    "\n",
    "# shrinkage \n",
    "function shrinkage(x, kappa) \n",
    "\n",
    "    z = 0*x ; \n",
    "    for i = 1:length(x) \n",
    "        z[i] = max( 0, x[i] - kappa ) - max( 0, -x[i] - kappa ) \n",
    "    end \n",
    "\n",
    "    return z \n",
    "end \n",
    "\n",
    "# test shrinkage \n",
    "kappa = 0.1 ; \n",
    "z = shrinkage(x, kappa) ; \n",
    "println(\"shrinkage z = \", z)\n",
    "\n",
    "# cache factorization \n",
    "function factor(A, rho)\n",
    "\n",
    "    m,n =  size(A) ; \n",
    "    if m >= n \n",
    "        C = cholesky( A'*A + rho*I ) \n",
    "    else\n",
    "        C = cholesky( I + 1/rho*(A*A') )  \n",
    "    end \n",
    "    L = C.L  \n",
    "    U = C.U \n",
    "\n",
    "    return L, U \n",
    "end \n",
    "\n",
    "# test \n",
    "rho = 0.1 \n",
    "L, U = factor(A, rho) \n",
    "\n",
    "# end \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual ADMM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: \"struct\" expression not at top level",
     "output_type": "error",
     "traceback": [
      "syntax: \"struct\" expression not at top level",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[15]:1",
      " [2] eval",
      "   @ .\\boot.jl:368 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1428"
     ]
    }
   ],
   "source": [
    "function lasso_admm(A, b, lamda, rho, alpha) \n",
    "# ------------------------------------------------------------------------\n",
    "# lasso  Solve lasso problem via ADMM\n",
    "#\n",
    "# [z, history] = lasso(A, b, lambda, rho, alpha);\n",
    "#\n",
    "# Solves the following problem via ADMM:\n",
    "#\n",
    "#   minimize 1/2*|| Ax - b ||_2^2 + \\lambda || x ||_1\n",
    "#\n",
    "# The solution is returned in the vector x.\n",
    "#\n",
    "# history is a structure that contains:\n",
    "#   objval   = objective function values \n",
    "#   r_norm   = primal residual norms \n",
    "#   s_norm   = dual residual norms \n",
    "#   eps_pri  = tolerances for the primal norms at each iteration\n",
    "#   eps_dual = tolerance for dual residual norms at each iteration\n",
    "#\n",
    "# rho is the augmented Lagrangian parameter.\n",
    "#\n",
    "# alpha is the over-relaxation parameter (typical values for alpha are\n",
    "# between 1.0 and 1.8).\n",
    "# \n",
    "# Reference: \n",
    "# http://www.stanford.edu/~boyd/papers/distr_opt_stat_learning_admm.html\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "    # # define output hist struct \n",
    "    # struct Hist \n",
    "    #     objval \n",
    "    #     r_norm \n",
    "    #     s_norm \n",
    "    #     eps_pri \n",
    "    #     eps_dual \n",
    "    # end \n",
    "    # hist = Hist([], [], [], [], [])\n",
    "\n",
    "    # define constants \n",
    "    max_iter = 1000  \n",
    "    abstol   = 1e-4 \n",
    "    reltol   = 1e-2 \n",
    "\n",
    "    # data pre-processing \n",
    "    m, n = size(A) \n",
    "    Atb = A'*b                          # save matrix-vector multiply \n",
    "\n",
    "    # ADMM solver \n",
    "    x = 0*b  \n",
    "    z = 0*b \n",
    "    u = 0*b \n",
    "\n",
    "    # cache factorization \n",
    "    L, U = factor(A, rho) \n",
    "\n",
    "    # begin iterations \n",
    "    for k = 1:max_iter \n",
    "\n",
    "        # x-update \n",
    "        q = Atb + rho*(z - u)           # temp value \n",
    "        if m >= n                       # if skinny \n",
    "            x = U \\ ( L \\ q ) \n",
    "        else                            # if fat \n",
    "            x = q / rho - ( A' * ( U \\ ( L \\ (A*q) ) ) ) / rho^2 \n",
    "        end \n",
    "\n",
    "        # z-update \n",
    "        z_old = z \n",
    "        x_hat = alpha*x + (1 - alpha*z_old) \n",
    "        z = shrinkage(x_hat + u, lambda/rho) \n",
    "\n",
    "        # u-update \n",
    "        u = u + (x_hat - z) \n",
    "\n",
    "        # # diagnostics + termination checks \n",
    "        # p = objective(A, b, lambda, x, z) \n",
    "        # push!( hist.objval, p )\n",
    "        # push!( hist.r_norm, norm(x - z) )\n",
    "        # push!( hist.s_norm, norm( -rho*(z - z_old) ) )\n",
    "        # push!( hist.eps_pri, sqrt(n)*abstol + reltol*max(norm(x), norm(-z)) ) \n",
    "        # push!( hist.eps_dual, sqrt(n)*abstol + reltol*norm(rho*u) ) \n",
    "\n",
    "        # if hist.r_norm[k] < hist.eps_pri[k] && hist.s_norm[k] < hist.eps_dual[k] \n",
    "        #     break \n",
    "        # end \n",
    "\n",
    "    end \n",
    "\n",
    "    return z, hist\n",
    "end \n",
    "\n",
    "# test \n",
    "x, hist = lasso_admm(A, b, lambda, 1.0, 1.0) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
